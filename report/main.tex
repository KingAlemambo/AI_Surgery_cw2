\documentclass[runningheads]{llncs}

\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{hyperref}

% For placeholder text - remove in final version
\newcommand{\todo}[1]{\textcolor{red}{[TODO: #1]}}
\newcommand{\result}[1]{\textcolor{blue}{#1}}

\begin{document}

\title{Temporal Context for Surgical Workflow Analysis: Duration Prediction and Tool Detection in Cholecystectomy}

\author{George Mathios}
\institute{University College London, Department of Medical Physics and Biomedical Engineering}

\maketitle

% ============================================================================
% ABSTRACT
% ============================================================================
\begin{abstract}
Accurate prediction of surgical duration and tool usage is essential for operating room scheduling, resource allocation, and intraoperative decision support. We present a deep learning framework for surgical workflow analysis using the Cholec80 dataset of laparoscopic cholecystectomy videos. Our approach combines a pretrained ResNet-50 feature extractor with a Long Short-Term Memory (LSTM) network for temporal modeling. For duration prediction (Task A), we predict remaining phase and surgery duration, as well as the start and end times of all surgical phases, achieving a mean absolute error of 7.27 minutes for current phase prediction and 13.80 minutes for total surgery remaining time. For tool detection (Task B), we investigate whether estimated temporal information can improve surgical tool detection through multi-task learning. We compare a baseline model against a time-augmented version that incorporates predicted surgical progress. Our experiments demonstrate \todo{add Task B conclusion}. We provide ablation studies on sequence length, CNN fine-tuning strategies, and the effect of temporal features on tool detection performance.

\keywords{Surgical workflow analysis \and Duration prediction \and Tool detection \and Deep learning \and LSTM}
\end{abstract}

% ============================================================================
% INTRODUCTION
% ============================================================================
\section{Introduction}

\subsection{Clinical Motivation}

Laparoscopic cholecystectomy is one of the most frequently performed surgical procedures worldwide, with over 1.2 million operations annually in the United States alone~\cite{twinanda2016endonet}. Despite its routine nature, surgical duration varies considerably between patients due to anatomical differences, complications, and surgeon experience. Accurate prediction of surgical duration and workflow progression has significant clinical value:

\begin{itemize}
    \item \textbf{Operating Room Scheduling}: Improved duration estimates enable better scheduling of subsequent procedures, reducing staff overtime and patient waiting times.
    \item \textbf{Resource Allocation}: Knowing which tools will be needed and when allows for better preparation of surgical instruments.
    \item \textbf{Intraoperative Decision Support}: Real-time awareness of surgical progress can alert teams to procedures running longer than expected, potentially indicating complications.
\end{itemize}

\subsection{Related Work}

Surgical workflow analysis has been extensively studied using the Cholec80 dataset~\cite{twinanda2016endonet}. EndoNet demonstrated that multi-task learning of phase recognition and tool detection yields mutual benefits, as tools and phases are inherently correlated. Recent work has explored temporal models including LSTMs, Temporal Convolutional Networks (TeCNO)~\cite{czempiel2020tecno}, and Transformers for capturing the sequential nature of surgery.

However, most prior work focuses on phase recognition rather than explicit duration prediction. Predicting \textit{when} phases will start and end, and \textit{how long} the surgery will take, remains less explored despite its practical importance for OR management.

\subsection{Research Questions}

In this work, we address the following research questions:

\textbf{RQ1}: How does temporal context length affect surgical duration prediction accuracy? We hypothesize that longer sequences provide more information but may introduce noise from older, less relevant frames.

\textbf{RQ2}: Can multi-output prediction of all phase start and end times provide useful surgical timeline estimates beyond single-target duration regression?

\textbf{RQ3}: Does incorporating predicted temporal information (from Task A) improve downstream tool detection (Task B)? We hypothesize that knowing the surgical progress helps predict which tools are likely to be present, as certain tools are phase-specific (e.g., Clipper in ClippingCutting phase, SpecimenBag in GallbladderPackaging).

\subsection{Contributions}

Our main contributions are:
\begin{enumerate}
    \item A CNN-LSTM architecture for multi-output surgical duration prediction, including phase-specific start and end times for all seven surgical phases.
    \item Systematic ablation studies on sequence length and CNN fine-tuning strategies for duration prediction.
    \item Investigation of whether predicted temporal features improve tool detection in a multi-task learning framework following the EndoNet approach.
\end{enumerate}

% ============================================================================
% METHODS
% ============================================================================
\section{Methods}

\subsection{Problem Formulation}

Given a sequence of $T$ video frames from an ongoing surgery, we aim to predict:

\textbf{Task A (Duration Prediction):}
\begin{itemize}
    \item Time remaining in current phase (minutes)
    \item Time remaining until surgery end (minutes)
    \item Start time of each of the 7 phases relative to current time (minutes)
    \item End time of each of the 7 phases relative to current time (minutes)
\end{itemize}

\textbf{Task B (Tool Detection):}
\begin{itemize}
    \item Presence/absence of 7 surgical tools (multi-label binary classification)
    \item Current surgical phase (multi-class classification, as auxiliary task)
\end{itemize}

\subsection{Architecture}

Our architecture follows a two-stage design: spatial feature extraction followed by temporal modeling (Figure~\ref{fig:architecture}).

\textbf{Spatial Feature Extraction (CNN):}
We use ResNet-50~\cite{he2016deep} pretrained on ImageNet as our backbone. The final classification layer is removed, yielding a 2048-dimensional feature vector per frame. We investigated two fine-tuning strategies:
\begin{itemize}
    \item \textit{Frozen}: All CNN weights fixed; only the temporal model learns.
    \item \textit{Partial unfreezing}: Layer4 (final residual block) is trainable while earlier layers remain frozen.
\end{itemize}

The rationale for partial unfreezing is that early CNN layers learn generic visual features (edges, textures) that transfer well across domains, while deeper layers learn task-specific features that benefit from adaptation to surgical imagery.

\textbf{Temporal Modeling (LSTM):}
Frame features are processed by a 2-layer LSTM with hidden dimension 256. The LSTM captures temporal dependencies and surgical progression patterns. We use dropout ($p=0.3$) between LSTM layers for regularization. The final hidden state is passed to task-specific prediction heads.

\textbf{Task A Prediction Heads:}
\begin{itemize}
    \item Phase remaining time: Linear layer outputting 1 value
    \item Surgery remaining time: Linear layer outputting 1 value
    \item Phase start times: Linear layer outputting 7 values
    \item Phase end times: Linear layer outputting 7 values
\end{itemize}

\textbf{Task B Prediction Heads:}
\begin{itemize}
    \item Tool detection: Linear layer with 7 outputs (sigmoid activation)
    \item Phase classification: Linear layer with 7 outputs (softmax activation)
\end{itemize}

\subsection{Time-Augmented Tool Detection}

For the ``timed'' version of Task B, we concatenate temporal features with CNN features before the LSTM:
\begin{equation}
    \mathbf{f}_t^{timed} = [\mathbf{f}_t^{CNN}; t_{elapsed}; p_{progress}]
\end{equation}
where $t_{elapsed}$ is the normalized elapsed time since surgery start, and $p_{progress}$ is the fraction of surgery completed. This allows the model to leverage temporal context when predicting tools.

\subsection{Loss Functions}

\textbf{Task A:} We use L1 loss (Mean Absolute Error) for all regression targets:
\begin{equation}
    \mathcal{L}_A = \text{L1}(\hat{t}_{phase}) + \text{L1}(\hat{t}_{surgery}) + \text{L1}(\hat{t}_{starts}) + \text{L1}(\hat{t}_{ends})
\end{equation}
L1 loss is preferred over L2 as it is less sensitive to outliers and produces predictions in clinically interpretable units (minutes).

\textbf{Task B:} Combined multi-task loss:
\begin{equation}
    \mathcal{L}_B = \text{BCE}(\hat{y}_{tools}, y_{tools}) + \text{CE}(\hat{y}_{phase}, y_{phase})
\end{equation}
For tool detection, we use Binary Cross-Entropy with class-weighted \texttt{pos\_weight} to handle tool imbalance. Rare tools like SpecimenBag (6.6\% frequency) receive higher weight than common tools like Grasper (60.6\%).

\subsection{Training Details}

\begin{itemize}
    \item \textbf{Optimizer}: AdamW with weight decay $10^{-4}$
    \item \textbf{Learning rate}: $10^{-4}$ with ReduceLROnPlateau scheduler
    \item \textbf{Batch size}: 8 sequences
    \item \textbf{Early stopping}: Patience of 5 epochs based on validation metric
    \item \textbf{Data augmentation}: Random crop ($256 \rightarrow 224$), horizontal flip ($p=0.5$), color jitter
\end{itemize}

% ============================================================================
% EXPERIMENTS
% ============================================================================
\section{Experiments}

\subsection{Dataset}

We use the \textbf{Cholec80} dataset~\cite{twinanda2016endonet}, consisting of 80 videos of laparoscopic cholecystectomy performed by 13 surgeons. The dataset includes frame-level annotations for 7 surgical phases and 7 surgical tools. Video durations range from approximately 20 to 80 minutes.

\textbf{Surgical Phases}: Preparation, Calot Triangle Dissection, Clipping and Cutting, Gallbladder Dissection, Gallbladder Packaging, Cleaning and Coagulation, Gallbladder Retraction.

\textbf{Surgical Tools}: Grasper, Bipolar, Hook, Scissors, Clipper, Irrigator, SpecimenBag.

\subsection{Data Split and Preprocessing}

We split the data by video (not by frame) to prevent data leakage:
\begin{itemize}
    \item Training: 48 videos (60\%)
    \item Validation: 16 videos (20\%)
    \item Test: 16 videos (20\%)
\end{itemize}

Frames are extracted at 1 fps from the original 25 fps videos and normalized using ImageNet statistics.

\subsection{Evaluation Metrics}

\textbf{Task A - Duration Prediction:}
\begin{itemize}
    \item Mean Absolute Error (MAE) in minutes --- clinically interpretable
\end{itemize}

\textbf{Task B - Tool Detection:}
\begin{itemize}
    \item Mean Average Precision (mAP) --- standard metric for multi-label classification
    \item Per-tool Average Precision (AP) --- identifies which tools are hardest to detect
    \item Phase Accuracy --- for the auxiliary phase classification task
\end{itemize}

\subsection{Ablation Studies}

\textbf{Sequence Length (Task A):} We compare $T \in \{15, 30, 60\}$ frames (at 1 fps, corresponding to 15, 30, 60 seconds of temporal context).

\textbf{CNN Fine-tuning (Task A):} We compare fully frozen CNN versus unfreezing Layer4.

\textbf{Time Features (Task B):} We compare baseline (no time features) versus timed (with elapsed time and progress).

% ============================================================================
% RESULTS
% ============================================================================
\section{Results}

\subsection{Task A: Duration Prediction}

\subsubsection{Effect of Sequence Length}

Table~\ref{tab:seq_length} shows the effect of temporal context length on duration prediction performance.

\begin{table}[h]
\centering
\caption{Effect of sequence length on duration prediction (MAE in minutes).}
\label{tab:seq_length}
\begin{tabular}{lccc}
\toprule
Sequence Length & Phase Remaining & Surgery Remaining \\
\midrule
$T = 15$ & 7.48 & 14.03 \\
$T = 30$ & \textbf{7.27} & \textbf{13.80} \\
$T = 60$ & 7.52 & 14.48 \\
\bottomrule
\end{tabular}
\end{table}

The optimal sequence length is $T=30$ frames (30 seconds of context). Shorter sequences lack sufficient temporal context, while longer sequences may introduce noise from frames too distant from the current surgical state.

\textbf{Clinical Interpretation:} A surgery duration prediction error of approximately 14 minutes is clinically meaningful for OR scheduling. For a typical 45-minute cholecystectomy, this represents roughly 30\% uncertainty.

\subsubsection{Phase Start and End Time Prediction}

Table~\ref{tab:phase_times} shows the prediction accuracy for individual phase start and end times.

\begin{table}[h]
\centering
\caption{Phase start and end time prediction (MAE in minutes, $T=30$).}
\label{tab:phase_times}
\begin{tabular}{lcc}
\toprule
Phase & Start Time MAE & End Time MAE \\
\midrule
Preparation & \result{X.XX} & \result{X.XX} \\
Calot Triangle Dissection & \result{X.XX} & \result{X.XX} \\
Clipping and Cutting & \result{X.XX} & \result{X.XX} \\
Gallbladder Dissection & \result{X.XX} & \result{X.XX} \\
Gallbladder Packaging & \result{X.XX} & \result{X.XX} \\
Cleaning and Coagulation & \result{X.XX} & \result{X.XX} \\
Gallbladder Retraction & \result{X.XX} & \result{X.XX} \\
\midrule
\textbf{Average} & \result{X.XX} & \result{X.XX} \\
\bottomrule
\end{tabular}
\end{table}

\todo{Fill in results and add interpretation}

\subsection{Task B: Tool Detection}

Table~\ref{tab:taskb} compares the baseline model (no time features) against the time-augmented model.

\begin{table}[h]
\centering
\caption{Tool detection performance: Baseline vs Time-Augmented.}
\label{tab:taskb}
\begin{tabular}{lccc}
\toprule
Model & mAP & Phase Accuracy \\
\midrule
Baseline (no time) & \result{X.XXX} & \result{X.XX} \\
Timed (with time features) & \result{X.XXX} & \result{X.XX} \\
\midrule
Improvement & \result{+X.XXX} & \result{+X.XX} \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Per-Tool Analysis}

Table~\ref{tab:per_tool} shows per-tool Average Precision for both models.

\begin{table}[h]
\centering
\caption{Per-tool Average Precision comparison.}
\label{tab:per_tool}
\begin{tabular}{lccc}
\toprule
Tool & Frequency & Baseline AP & Timed AP \\
\midrule
Grasper & 60.6\% & \result{X.XX} & \result{X.XX} \\
Hook & 55.5\% & \result{X.XX} & \result{X.XX} \\
SpecimenBag & 6.6\% & \result{X.XX} & \result{X.XX} \\
Irrigator & 6.5\% & \result{X.XX} & \result{X.XX} \\
Bipolar & 5.2\% & \result{X.XX} & \result{X.XX} \\
Clipper & 3.5\% & \result{X.XX} & \result{X.XX} \\
Scissors & 1.9\% & \result{X.XX} & \result{X.XX} \\
\bottomrule
\end{tabular}
\end{table}

\todo{Add analysis of which tools benefit most from time features}

% ============================================================================
% DISCUSSION
% ============================================================================
\section{Discussion}

\todo{Summarize key findings}

\textbf{Limitations:}
\begin{itemize}
    \item \textbf{Single dataset}: Results may not generalize to other surgical procedures or institutions.
    \item \textbf{Class imbalance}: Rare tools (SpecimenBag, Scissors) remain challenging despite class weighting.
    \item \textbf{Temporal resolution}: 1 fps sampling may miss rapid tool changes.
\end{itemize}

\textbf{Clinical Implications:} \todo{Discuss practical value}

% ============================================================================
% CONCLUSION
% ============================================================================
\section{Conclusion}

\todo{Summarize findings and future work}

Future directions include exploring Transformer-based temporal modeling, incorporating patient-specific features (BMI, previous surgeries), and investigating real-time deployment considerations.

% ============================================================================
% REFERENCES
% ============================================================================
\bibliographystyle{splncs04}
\begin{thebibliography}{9}

\bibitem{twinanda2016endonet}
Twinanda, A.P., Shehata, S., Mutter, D., Marescaux, J., De Mathelin, M., Padoy, N.: EndoNet: A deep architecture for recognition tasks on laparoscopic videos. IEEE Transactions on Medical Imaging \textbf{36}(1), 86--97 (2016)

\bibitem{czempiel2020tecno}
Czempiel, T., Paber, M., Shehata, S., Stypulkowski, M., Ostler, D., Navab, N., Tombari, F.: TeCNO: Surgical phase recognition with multi-stage temporal convolutional networks. In: MICCAI 2020. pp. 343--352 (2020)

\bibitem{he2016deep}
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: CVPR. pp. 770--778 (2016)

\end{thebibliography}

\end{document}
