\documentclass[runningheads]{llncs}

\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{hyperref}

% For placeholder text - remove in final version
\newcommand{\todo}[1]{\textcolor{red}{[TODO: #1]}}
\newcommand{\result}[1]{\textcolor{blue}{#1}}

\begin{document}

\title{Temporal Context for Surgical Workflow Analysis: Duration Prediction and Tool Detection in Cholecystectomy}

\author{Alexandros Mathios}
\institute{University College London, Department of Medical Physics and Biomedical Engineering}

\maketitle

% ============================================================================
% ABSTRACT
% ============================================================================
\begin{abstract}
Accurate prediction of surgical duration and tool usage is essential for operating room scheduling and intraoperative decision support. We present a CNN-LSTM framework for surgical workflow analysis using the Cholec80 dataset. For duration prediction (Task A), we predict remaining phase and surgery time, achieving 7.27 and 13.80 minutes MAE respectively. For tool detection (Task B), we investigate whether \textit{predicted} timing from Task A improves performance. Comparing a baseline against a time-augmented model using frozen Task A predictions, we find that predicted temporal context (0.954 mAP) performs worse than the baseline (0.960 mAP), while ground-truth elapsed time shows improvement (0.962 mAP)---indicating that Task A predictions require higher accuracy before benefiting downstream tasks.

\keywords{Surgical workflow analysis \and Duration prediction \and Tool detection \and Deep learning \and LSTM}
\end{abstract}

% ============================================================================
% INTRODUCTION
% ============================================================================
\section{Introduction}

\subsection{Clinical Motivation}

Laparoscopic cholecystectomy is one of the most frequently performed surgical procedures worldwide, with over 1.2 million operations annually in the United States alone~\cite{twinanda2016endonet}. Despite its routine nature, surgical duration varies considerably between patients due to anatomical differences, complications, and surgeon experience. Accurate prediction of surgical duration and workflow progression has significant clinical value:

\begin{itemize}
    \item \textbf{Operating Room Scheduling}: Improved duration estimates enable better scheduling of subsequent procedures, reducing staff overtime and patient waiting times.
    \item \textbf{Resource Allocation}: Knowing which tools will be needed and when allows for better preparation of surgical instruments.
    \item \textbf{Intraoperative Decision Support}: Real-time awareness of surgical progress can alert teams to procedures running longer than expected, potentially indicating complications.
\end{itemize}

\subsection{Research Questions}

In this work, we address the following research questions:

\textbf{RQ1}: How does temporal context length affect surgical duration prediction accuracy? We hypothesize that longer sequences provide more information but may introduce noise from older, less relevant frames.

\textbf{RQ2}: Can multi-output prediction of all phase start and end times provide useful surgical timeline estimates beyond single-target duration regression?

\textbf{RQ3}: Does incorporating predicted temporal information (from Task A) improve downstream tool detection (Task B)? We hypothesize that knowing the surgical progress helps predict which tools are likely to be present, as certain tools are phase-specific (e.g., Clipper in ClippingCutting phase, SpecimenBag in GallbladderPackaging).

% ============================================================================
% METHODS
% ============================================================================
\section{Methods}

\subsection{Architecture}

We design a unified video-based pipeline for surgical workflow analysis consisting of three stages: (1) frame-level visual feature extraction, (2) temporal modelling across frame sequences, and (3) task-specific prediction heads. Video frames are sampled at 1 fps and grouped into fixed-length sequences of $T$ frames.

\textbf{Visual Features:} We use ResNet-50~\cite{he2016deep} pretrained on ImageNet, producing a \textbf{2048-dimensional feature vector per frame}. To balance adaptation and regularisation, we apply \textbf{partial fine-tuning}: early layers are frozen while the final residual block (Layer4) is trainable, allowing adaptation to laparoscopic imagery while preserving robust low-level features~\cite{yosinski2014transferable}.

\textbf{Temporal Modelling:} Frame features are processed by a \textbf{two-layer LSTM} with hidden dimension \textbf{256}. The final hidden state serves as the shared temporal representation for all downstream predictions, capturing both short-term patterns (e.g., tool motion) and longer-term trends (e.g., phase progression).

\subsection{Task A: Duration Prediction}

For Task A, the model receives a sequence of frames along with \textbf{normalised elapsed time} as input. The LSTM output is fed into \textbf{multiple regression heads} predicting: the remaining time of the current surgical phase, the total surgery time, and start/end times of all 7 surgical phases (relative to current time).

Predicting complete phase timelines provides more informative scheduling estimates than single duration values. All outputs use \textbf{L1 loss}, which is robust to surgical duration variability and yields errors interpretable in minutes.

\subsection{Task B: Tool Detection with Temporal Information}

Task B evaluates whether temporal information estimated in Task A can improve a downstream task. We select \textbf{surgical tool detection}, as tool usage is strongly correlated with surgical phase~\cite{twinanda2016endonet}.

The same CNN--LSTM backbone is reused with two task-specific heads:
\begin{itemize}
    \item A \textbf{multi-label tool detection head} with 7 sigmoid outputs
    \item A \textbf{phase classification head} with 7 softmax outputs (auxiliary task)
\end{itemize}

This multi-task design follows EndoNet~\cite{twinanda2016endonet}, leveraging tool-phase correlations. Binary cross-entropy with \textbf{class weighting} addresses tool imbalance (Grasper: 60.6\% vs Scissors: 1.9\%).

\textbf{Time-Augmented Model:} The predicted remaining surgery time from a \textbf{frozen Task A model} is concatenated to CNN features before the LSTM. Critically, we use predicted time rather than ground-truth, testing whether Task A estimates provide useful context in a realistic deployment scenario.

\subsection{Training Strategy}

\textbf{Optimisation:} We use AdamW~\cite{loshchilov2019adamw} with ReduceLROnPlateau scheduling, reducing the learning rate when validation performance plateaus.

\textbf{Regularisation:} We combine dropout between LSTM layers~\cite{gal2016dropout}, weight decay, early stopping, and partial CNN freezing to prevent overfitting.

\textbf{Data Augmentation:} Random cropping, horizontal flipping, and colour jitter simulate OR visual variations. Vertical flipping is not used as surgical orientation is clinically meaningful.

% ============================================================================
% EXPERIMENTS
% ============================================================================
\section{Experiments}

\subsection{Dataset}

We use the \textbf{Cholec80} dataset~\cite{twinanda2016endonet}, consisting of 80 videos of laparoscopic cholecystectomy performed by 13 surgeons. Video durations range from approximately 20 to 80 minutes. The dataset includes frame-level annotations for 7 surgical phases (Preparation, Calot Triangle Dissection, Clipping and Cutting, Gallbladder Dissection, Gallbladder Packaging, Cleaning and Coagulation, Gallbladder Retraction) and 7 surgical tools (Grasper, Bipolar, Hook, Scissors, Clipper, Irrigator, SpecimenBag).

\subsection{Experimental Setup}

We split the data by video (not by frame) to prevent data leakage from temporal correlations: 48 videos for training (60\%), 16 for validation (20\%), and 16 for testing (20\%). Frames are extracted at 1 fps from the original 25 fps videos and normalised using ImageNet statistics. Training uses learning rate $10^{-4}$, weight decay $10^{-4}$, batch size 8, and early stopping with patience of 5 epochs.

\subsection{Evaluation Metrics}

For \textbf{Task A} (duration prediction), we use Mean Absolute Error (MAE) measured in minutes. MAE provides directly interpretable errors in clinical time units---a prediction error of ``X minutes'' is immediately meaningful for operating room scheduling. Unlike RMSE, MAE is robust to outliers from unusually long or complicated surgeries.

For \textbf{Task B} (tool detection), we use Mean Average Precision (mAP), the standard metric for multi-label classification that summarises detection quality across all tools while handling class imbalance. We also report per-tool Average Precision (AP) to identify which specific tools are most challenging to detect---this is clinically relevant as rare tools like SpecimenBag and Scissors require particular attention. For the auxiliary phase classification task, we report classification accuracy.

\subsection{Task A: Duration Prediction Experiments}

We conduct a series of experiments to optimise duration prediction, systematically investigating architectural choices, temporal context, and regularisation.

\textbf{Frozen vs Unfrozen CNN:} We first compare two transfer learning strategies: (1) fully frozen CNN where all ResNet-50 weights are fixed, and (2) partial fine-tuning where the final residual block (Layer4) is trainable. This investigates whether the domain shift from ImageNet to laparoscopic imagery requires CNN adaptation, or whether frozen features suffice.

\textbf{Sequence Length Ablation:} We investigate how much temporal context is needed for accurate duration prediction by comparing sequence lengths $T \in \{15, 30, 60\}$ frames (corresponding to 15, 30, and 60 seconds at 1 fps). Shorter sequences may lack sufficient context about surgical progression, while longer sequences risk introducing noise from outdated visual information.

\textbf{Regularisation:} During initial experiments, we observed overfitting where training loss continued decreasing while validation loss plateaued or increased. To address this, we systematically applied multiple regularisation techniques: dropout between LSTM layers ($p=0.3$) and before prediction heads ($p=0.5$), weight decay ($10^{-4}$), early stopping based on validation performance, and partial CNN freezing to constrain the hypothesis space.

\textbf{Temporal Architecture Comparison:} To evaluate whether alternative temporal models could improve performance, we compare the LSTM-based architecture against a Transformer encoder with equivalent capacity (same hidden dimension, comparable parameter count). This tests whether the self-attention mechanism offers advantages over recurrent processing for surgical video sequences.

\subsection{Task B: Tool Detection Experiments}

Task B investigates whether predicted temporal information from Task A can improve surgical tool detection---the core question of whether duration estimates are useful for downstream tasks.

\textbf{Baseline Multi-task Model:} We first establish a baseline using the CNN-LSTM backbone with multi-task learning (tool detection + phase classification) but no temporal features. This follows the EndoNet approach~\cite{twinanda2016endonet}, exploiting the correlation between tools and surgical phases.

\textbf{Time-Augmented Model:} We then augment the model with predicted surgery remaining time from a frozen Task A model. Critically, we use \textit{predicted} time rather than ground-truth elapsed time---this reflects a realistic deployment scenario where true timing is unavailable, and directly tests whether Task A predictions provide useful context. The frozen Task A model generates predictions for each training batch, which are concatenated with CNN features before the LSTM.

\textbf{Per-Tool Analysis:} We analyse detection performance for each tool individually to understand which tools benefit from temporal information. We hypothesise that phase-specific tools (Clipper during ClippingCutting, SpecimenBag during GallbladderPackaging) will show greater improvement, as knowing surgical progress helps predict their presence.

% ============================================================================
% RESULTS
% ============================================================================
\section{Results}

\subsection{Task A: Duration Prediction}

\subsubsection{Effect of Sequence Length}

Table~\ref{tab:seq_length} shows the effect of temporal context length on duration prediction performance.

\begin{table}[h]
\centering
\caption{Effect of sequence length on duration prediction (MAE in minutes).}
\label{tab:seq_length}
\begin{tabular}{lccc}
\toprule
Sequence Length & Phase Remaining & Surgery Remaining \\
\midrule
$T = 15$ & 7.48 & 14.03 \\
$T = 30$ & \textbf{7.27} & \textbf{13.80} \\
$T = 60$ & 7.52 & 14.48 \\
\bottomrule
\end{tabular}
\end{table}

The optimal sequence length is $T=30$ frames (30 seconds of context). Shorter sequences lack sufficient temporal context for understanding surgical progression, while longer sequences introduce noise from outdated visual information. This finding aligns with the temporal dynamics of surgical phases, which typically evolve over tens of seconds rather than minutes.

\textbf{Clinical Interpretation:} A surgery duration prediction error of approximately 14 minutes is clinically relevant for OR scheduling. For a typical 45-minute cholecystectomy, this represents roughly 30\% uncertainty---sufficient for approximate scheduling but highlighting the inherent difficulty of duration prediction from visual information alone.

\subsubsection{LSTM vs Transformer}

We compared the LSTM temporal model against a Transformer encoder with equivalent capacity (d\_model=256, 8 attention heads, 2 layers). At $T=30$, LSTM achieves 7.27 min phase MAE versus Transformer's 7.59 min. The Transformer showed severe overfitting (train MAE: 1.79 min, val MAE: 7.85 min), triggering early stopping after 4 epochs. This suggests that for short sequences and limited data, LSTM's sequential inductive bias outperforms Transformer's learned attention patterns.

\subsection{Task B: Tool Detection}

Table~\ref{tab:taskb} compares tool detection performance across three conditions: baseline (no time features), time-augmented with ground-truth elapsed time, and time-augmented with predicted time from Task A.

\begin{table}[h]
\centering
\caption{Tool detection performance comparison.}
\label{tab:taskb}
\begin{tabular}{lcc}
\toprule
Model & mAP & Phase Accuracy \\
\midrule
Baseline (no time) & \textbf{0.960} & 89.2\% \\
+ Elapsed time (ground truth) & 0.962 & \textbf{90.5\%} \\
+ Predicted time (from Task A) & 0.954 & 88.6\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Finding:} The time-augmented model using \textit{predicted} time from Task A performs \textit{worse} than the baseline (0.954 vs 0.960 mAP). This contrasts with the ground-truth elapsed time condition, which shows modest improvement (0.962 mAP). This result indicates that while accurate temporal information can benefit tool detection, the noise in Task A predictions ($\sim$14 minute MAE) introduces more confusion than useful signal.

\subsubsection{Per-Tool Analysis}

Table~\ref{tab:per_tool} shows per-tool Average Precision for the predicted time model.

\begin{table}[h]
\centering
\caption{Per-tool Average Precision (predicted time model).}
\label{tab:per_tool}
\begin{tabular}{lcc}
\toprule
Tool & Frequency & AP \\
\midrule
Hook & 56.0\% & 0.994 \\
SpecimenBag & 6.8\% & 0.976 \\
Irrigator & 6.7\% & 0.968 \\
Bipolar & 5.3\% & 0.962 \\
Clipper & 3.6\% & 0.958 \\
Grasper & 60.5\% & 0.918 \\
Scissors & 1.8\% & 0.906 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Analysis:} Hook achieves the highest AP (0.994), likely due to its distinctive visual appearance during dissection. Grasper, despite being the most frequent tool (60.5\%), has lower AP (0.918) because it appears throughout surgery, making its \textit{absence} difficult to predict. Scissors shows the lowest AP (0.906), reflecting the challenge of detecting rare tools (1.8\% frequency) even with class weighting.

\subsubsection{Interpretation}

The comparison between ground-truth and predicted time reveals an important insight: temporal context \textit{can} improve tool detection when accurate, but the current Task A predictions are insufficiently precise. With $\sim$14 minute MAE on surgery remaining time (approximately 30\% error for a typical procedure), the predicted time signal contains substantial noise. The model may learn to partially ignore this unreliable input, or worse, be misled by incorrect temporal cues. This suggests that improving duration prediction accuracy is a prerequisite for effectively leveraging temporal context in downstream tasks.

% ============================================================================
% DISCUSSION
% ============================================================================
\section{Discussion}

Our experiments address three research questions with the following findings:

\textbf{RQ1 (Sequence Length):} The optimal temporal context is 30 seconds ($T=30$ frames). Shorter sequences lack sufficient context for understanding surgical progression, while longer sequences introduce noise from outdated visual information.

\textbf{RQ2 (Phase Timing Prediction):} Multi-output prediction of phase start/end times enables comprehensive surgical timeline estimation, though with $\sim$14 minute MAE for surgery remaining time ($\sim$30\% error for a typical procedure), the utility for fine-grained scheduling is limited.

\textbf{RQ3 (Predicted Time for Tool Detection):} Our hypothesis that predicted temporal information improves tool detection is \textit{not supported}. The predicted time model (0.954 mAP) performs \textit{worse} than the baseline (0.960 mAP). However, ground-truth elapsed time \textit{does} improve performance (0.962 mAP), indicating that accurate temporal context can benefit tool detection. The $\sim$14 minute MAE from Task A introduces more noise than signal---the model is misled by incorrect temporal cues rather than helped by approximate timing.

\textbf{Implications:} This negative result reveals a key challenge: downstream tasks require upstream predictions to exceed a quality threshold before providing benefit. Ground-truth timing helps, but predicted timing with 30\% error hurts. Improving Task A accuracy is therefore a prerequisite for leveraging temporal context in Task B.

\textbf{Limitations:} Results on Cholec80 may not generalise to other procedures. Class imbalance affects rare tools despite weighting. 1 fps sampling may miss brief tool appearances.

% ============================================================================
% CONCLUSION
% ============================================================================
\section{Conclusion}

We presented a CNN-LSTM framework for surgical workflow analysis addressing duration prediction and tool detection. For duration prediction (Task A), we achieved 7.27 minutes MAE for phase remaining time and 13.80 minutes for surgery remaining time, with optimal performance at 30-second temporal context. For tool detection (Task B), our baseline achieved 0.960 mAP. Augmenting with \textit{predicted} time from Task A reduced performance to 0.954 mAP, while ground-truth elapsed time improved it to 0.962 mAP.

Our key finding is a meaningful negative result: predicted temporal context hurts rather than helps tool detection when prediction accuracy is insufficient ($\sim$30\% error). This highlights that task chaining in surgical AI pipelines requires upstream predictions to meet minimum quality thresholds. Visual features remain the dominant signal for tool recognition, which is encouraging for real-world deployment where timing information may be unavailable or unreliable.

Future work should focus on improving duration prediction accuracy before attempting to leverage it for downstream tasks.

% ============================================================================
% REFERENCES
% ============================================================================
\bibliographystyle{splncs04}
\begin{thebibliography}{9}

\bibitem{twinanda2016endonet}
Twinanda, A.P., Shehata, S., Mutter, D., Marescaux, J., De Mathelin, M., Padoy, N.: EndoNet: A deep architecture for recognition tasks on laparoscopic videos. IEEE Transactions on Medical Imaging \textbf{36}(1), 86--97 (2016)

\bibitem{czempiel2020tecno}
Czempiel, T., Paber, M., Shehata, S., Stypulkowski, M., Ostler, D., Navab, N., Tombari, F.: TeCNO: Surgical phase recognition with multi-stage temporal convolutional networks. In: MICCAI 2020. pp. 343--352 (2020)

\bibitem{he2016deep}
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: CVPR. pp. 770--778 (2016)

\bibitem{yosinski2014transferable}
Yosinski, J., Clune, J., Bengio, Y., Lipson, H.: How transferable are features in deep neural networks? In: NeurIPS. pp. 3320--3328 (2014)

\bibitem{loshchilov2019adamw}
Loshchilov, I., Hutter, F.: Decoupled weight decay regularization. In: ICLR (2019)

\bibitem{gal2016dropout}
Gal, Y., Ghahramani, Z.: A theoretically grounded application of dropout in recurrent neural networks. In: NeurIPS. pp. 1019--1027 (2016)

\end{thebibliography}

\end{document}
